{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "# Set current directory\n",
    "%cd /home/jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model directory and copy the model parameters into this directory\n",
    "!mkdir -p \"model\"\n",
    "!cp \"/home/jupyter/bert-joint-baseline/bert_config.json\" \"model/\"\n",
    "!cp \"/home/jupyter/bert-joint-baseline/vocab-nq.txt\" \"model/\"\n",
    "!cp \"/home/jupyter/bert-joint-baseline/bert_joint.ckpt.data-00000-of-00001\" \"model/\"\n",
    "!cp \"/home/jupyter/bert-joint-baseline/bert_joint.ckpt.index\" \"model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this in TERMINAL to create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat <<'HERE' | tee Dockerfile\n",
    "# Docker file for submission of the BERT-joint baseline to the Natural Questions\n",
    "# competition site: https://ai.google.com/research/NaturalQuestions/competition.\n",
    "# ARG TF_VERSION=1.14\n",
    "# FROM tensorflow/tensorflow:$TF_VERSION\n",
    "FROM tensorflow/tensorflow:1.14.0-gpu-py3\n",
    "# Install the BERT and Natural Questions libraries.\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --trusted-host pypi.python.org bert-tensorflow \n",
    "RUN pip install --trusted-host pypi.python.org natural-questions --no-dependencies\n",
    "\n",
    "# Add everything in the current directory to a /nq_model directory in the\n",
    "# Docker container.\n",
    "ADD . /nq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this in TERMINAL to create submission script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission.sh \n",
    "!cat <<'HERE' | tee submission.sh\n",
    "#!/bin/bash\n",
    "#\n",
    "# submission.sh: The script to be launched in the Docker image.\n",
    "#\n",
    "# Usage: submission.sh <input_data_pattern> <output_file>\n",
    "#   input_data_pattern: jsonl.gz NQ evaluation files,\n",
    "#   output_file: json file containing answer key produced by the model.\n",
    "#\n",
    "# Sample usage:\n",
    "#   submission.sh nq-dev-0?.jsonl.gz predictions.json\n",
    "\n",
    "set -e\n",
    "set -x\n",
    "\n",
    "INPUT_PATH=$1\n",
    "OUTPUT_PATH=$2\n",
    "\n",
    "cd /nq_model\n",
    "pwd\n",
    "python3 -m run_nq \\\n",
    "  --logtostderr \\\n",
    "  --bert_config_file=\"/nq_model/model/bert_config.json\" \\\n",
    "  --vocab_file=\"/nq_model/model/vocab-nq.txt\" \\\n",
    "  --init_checkpoint=\"/nq_model/model/bert_joint.ckpt\" \\\n",
    "  --output_dir=\"/tmp\" \\\n",
    "  --do_predict \\\n",
    "  --predict_file=\"$INPUT_PATH\" \\\n",
    "  --output_prediction_file=\"$OUTPUT_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  1.341GB\n",
      "Step 1/5 : FROM tensorflow/tensorflow:1.14.0-gpu-py3\n",
      " ---> a7a1861d2150\n",
      "Step 2/5 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 44fdf6aa1baf\n",
      "Step 3/5 : RUN pip install --trusted-host pypi.python.org bert-tensorflow\n",
      " ---> Using cache\n",
      " ---> 5c588ef65f44\n",
      "Step 4/5 : RUN pip install --trusted-host pypi.python.org natural-questions --no-dependencies\n",
      " ---> Using cache\n",
      " ---> 970f961db0f3\n",
      "Step 5/5 : ADD . /nq_model\n",
      " ---> 97296f0a93c7\n",
      "Successfully built 97296f0a93c7\n",
      "Successfully tagged nq-submission-bert-joint:latest\n"
     ]
    }
   ],
   "source": [
    "# Build the Docker image using Dockerfile and submission.sh in the current directory\n",
    "IMAGE_NAME=\"nq-submission-bert-joint\"\n",
    "!docker build --tag=$IMAGE_NAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Docker image on  dev set sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount the small dev-sample into a temporary directory within the container\n",
    "DATA_DIR=\"/tmp/nq-submission-test-data\"\n",
    "!mkdir -p \"$DATA_DIR\"\n",
    "!gsutil cp -R \"gs://bert-nq/tiny-dev\" \"$DATA_DIR\"\n",
    "\n",
    "# Run the Docker image with dev set as input and predictions.json as output\n",
    "!docker run --runtime=nvidia -a stdin -a stdout -a stderr -v \"$DATA_DIR\":/data \\\n",
    "    \"$IMAGE_NAME\" bash \"/nq_model/submission.sh\" \\\n",
    "    \"/data/tiny-dev/nq-dev-sample.jsonl.gz\" \\\n",
    "    \"/data/predictions.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/absl/flags/_validators.py:359: UserWarning: Flag --gold_path has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "/opt/conda/lib/python3.7/site-packages/absl/flags/_validators.py:359: UserWarning: Flag --predictions_path has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "I0322 23:32:53.321207 140454025184640 eval_utils.py:261] parsing /tmp/nq-submission-test-data/tiny-dev/nq-dev-sample.jsonl.gz ..... \n",
      "I0322 23:32:56.733036 140454025184640 eval_utils.py:213] Reading predictions from file: /tmp/nq-submission-test-data/predictions.json\n",
      "{\"long-best-threshold-f1\": 0.6325581395348837, \"long-best-threshold-precision\": 0.6071428571428571, \"long-best-threshold-recall\": 0.6601941747572816, \"long-best-threshold\": 5.9293248653411865, \"long-recall-at-precision>=0.5\": 0.6893203883495146, \"long-precision-at-precision>=0.5\": 0.5107913669064749, \"long-recall-at-precision>=0.75\": 0.3786407766990291, \"long-precision-at-precision>=0.75\": 0.7959183673469388, \"long-recall-at-precision>=0.9\": 0.0970873786407767, \"long-precision-at-precision>=0.9\": 0.9090909090909091, \"short-best-threshold-f1\": 0.5806451612903226, \"short-best-threshold-precision\": 0.7346938775510204, \"short-best-threshold-recall\": 0.48, \"short-best-threshold\": 9.65334838628769, \"short-recall-at-precision>=0.5\": 0.52, \"short-precision-at-precision>=0.5\": 0.52, \"short-recall-at-precision>=0.75\": 0.4533333333333333, \"short-precision-at-precision>=0.75\": 0.7906976744186046, \"short-recall-at-precision>=0.9\": 0.13333333333333333, \"short-precision-at-precision>=0.9\": 0.9090909090909091}\n"
     ]
    }
   ],
   "source": [
    "# Check that prediction scores are compuated as expected\n",
    "!python3 -m nq_eval \\\n",
    "  --gold_path=\"$DATA_DIR/tiny-dev/nq-dev-sample.jsonl.gz\" \\\n",
    "  --predictions_path=\"$DATA_DIR/predictions.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are running on a Google Compute Engine virtual machine.\n",
      "It is recommended that you use service accounts for authentication.\n",
      "\n",
      "You can run:\n",
      "\n",
      "  $ gcloud config set account `ACCOUNT`\n",
      "\n",
      "to switch accounts if necessary.\n",
      "\n",
      "Your credentials may be visible to others with access to this\n",
      "virtual machine. Are you sure you want to authenticate with\n",
      "your personal account?\n",
      "\n",
      "Do you want to continue (Y/n)?  ^C\n",
      "\n",
      "\n",
      "Command killed by keyboard interrupt\n",
      "\n",
      "Updated property [core/project].\n",
      "Creating temporary tarball archive of 16 file(s) totalling 1.2 GiB before compression.\n",
      "Uploading tarball of [.] to [gs://natural-questions-v1_cloudbuild/source/1584923304.9-3d97c16d9850449b96b36bb20c962c72.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/natural-questions-v1/builds/c108bb97-9286-4241-ade1-615e2163ecce].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/c108bb97-9286-4241-ade1-615e2163ecce?project=512516930043].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"c108bb97-9286-4241-ade1-615e2163ecce\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://natural-questions-v1_cloudbuild/source/1584923304.9-3d97c16d9850449b96b36bb20c962c72.tgz#1584923387754774\n",
      "Copying gs://natural-questions-v1_cloudbuild/source/1584923304.9-3d97c16d9850449b96b36bb20c962c72.tgz#1584923387754774...\n",
      "- [1 files][  1.2 GiB/  1.2 GiB]   59.8 MiB/s                                   \n",
      "Operation completed over 1 objects/1.2 GiB.                                      \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  1.341GB\n",
      "Step 1/5 : FROM tensorflow/tensorflow:1.14.0-gpu-py3\n",
      "1.14.0-gpu-py3: Pulling from tensorflow/tensorflow\n",
      "6abc03819f3e: Pulling fs layer\n",
      "05731e63f211: Pulling fs layer\n",
      "0bd67c50d6be: Pulling fs layer\n",
      "d5c73556cc1e: Pulling fs layer\n",
      "e059dd98ac7c: Pulling fs layer\n",
      "e4732fdd9b39: Pulling fs layer\n",
      "cbeb255d6ab1: Pulling fs layer\n",
      "0809e577f6d6: Pulling fs layer\n",
      "421e23cecfe8: Pulling fs layer\n",
      "a5abf0996067: Pulling fs layer\n",
      "d718e4299c08: Pulling fs layer\n",
      "f401bdaa92ad: Pulling fs layer\n",
      "6669e38ab1ba: Pulling fs layer\n",
      "5b6ac7f35d3d: Pulling fs layer\n",
      "d5c73556cc1e: Waiting\n",
      "e059dd98ac7c: Waiting\n",
      "e4732fdd9b39: Waiting\n",
      "0809e577f6d6: Waiting\n",
      "421e23cecfe8: Waiting\n",
      "a5abf0996067: Waiting\n",
      "d718e4299c08: Waiting\n",
      "f401bdaa92ad: Waiting\n",
      "6669e38ab1ba: Waiting\n",
      "5b6ac7f35d3d: Waiting\n",
      "cbeb255d6ab1: Waiting\n",
      "05731e63f211: Verifying Checksum\n",
      "05731e63f211: Download complete\n",
      "0bd67c50d6be: Verifying Checksum\n",
      "0bd67c50d6be: Download complete\n",
      "6abc03819f3e: Verifying Checksum\n",
      "6abc03819f3e: Download complete\n",
      "e059dd98ac7c: Verifying Checksum\n",
      "e059dd98ac7c: Download complete\n",
      "d5c73556cc1e: Verifying Checksum\n",
      "d5c73556cc1e: Download complete\n",
      "e4732fdd9b39: Verifying Checksum\n",
      "e4732fdd9b39: Download complete\n",
      "421e23cecfe8: Verifying Checksum\n",
      "421e23cecfe8: Download complete\n",
      "0809e577f6d6: Verifying Checksum\n",
      "0809e577f6d6: Download complete\n",
      "a5abf0996067: Verifying Checksum\n",
      "a5abf0996067: Download complete\n",
      "d718e4299c08: Verifying Checksum\n",
      "d718e4299c08: Download complete\n",
      "6669e38ab1ba: Verifying Checksum\n",
      "6669e38ab1ba: Download complete\n",
      "5b6ac7f35d3d: Download complete\n",
      "6abc03819f3e: Pull complete\n",
      "cbeb255d6ab1: Verifying Checksum\n",
      "cbeb255d6ab1: Download complete\n",
      "05731e63f211: Pull complete\n",
      "f401bdaa92ad: Verifying Checksum\n",
      "f401bdaa92ad: Download complete\n",
      "0bd67c50d6be: Pull complete\n",
      "d5c73556cc1e: Pull complete\n",
      "e059dd98ac7c: Pull complete\n",
      "e4732fdd9b39: Pull complete\n",
      "cbeb255d6ab1: Pull complete\n",
      "0809e577f6d6: Pull complete\n",
      "421e23cecfe8: Pull complete\n",
      "a5abf0996067: Pull complete\n",
      "d718e4299c08: Pull complete\n",
      "f401bdaa92ad: Pull complete\n",
      "6669e38ab1ba: Pull complete\n",
      "5b6ac7f35d3d: Pull complete\n",
      "Digest: sha256:e72e66b3dcb9c9e8f4e5703965ae1466b23fe8cad59e1c92c6e9fa58f8d81dc8\n",
      "Status: Downloaded newer image for tensorflow/tensorflow:1.14.0-gpu-py3\n",
      " ---> a7a1861d2150\n",
      "Step 2/5 : RUN pip install --upgrade pip\n",
      " ---> Running in 700f4b0204df\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 19.1.1\n",
      "    Uninstalling pip-19.1.1:\n",
      "      Successfully uninstalled pip-19.1.1\n",
      "Successfully installed pip-20.0.2\n",
      "Removing intermediate container 700f4b0204df\n",
      " ---> 08b0ea4727b8\n",
      "Step 3/5 : RUN pip install --trusted-host pypi.python.org bert-tensorflow\n",
      " ---> Running in 079d5b543a89\n",
      "Collecting bert-tensorflow\n",
      "  Downloading bert_tensorflow-1.0.1-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from bert-tensorflow) (1.11.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n",
      "Removing intermediate container 079d5b543a89\n",
      " ---> 0ed605742cb9\n",
      "Step 4/5 : RUN pip install --trusted-host pypi.python.org natural-questions --no-dependencies\n",
      " ---> Running in 17947dd37904\n",
      "Collecting natural-questions\n",
      "  Downloading natural_questions-1.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Installing collected packages: natural-questions\n",
      "Successfully installed natural-questions-1.0.4\n",
      "Removing intermediate container 17947dd37904\n",
      " ---> f475ed63e89f\n",
      "Step 5/5 : ADD . /nq_model\n",
      " ---> d31dfdaa30af\n",
      "Successfully built d31dfdaa30af\n",
      "Successfully tagged gcr.io/natural-questions-v1/nq-submission-bert-joint:latest\n",
      "PUSH\n",
      "Pushing gcr.io/natural-questions-v1/nq-submission-bert-joint\n",
      "The push refers to repository [gcr.io/natural-questions-v1/nq-submission-bert-joint]\n",
      "6d2b28061301: Preparing\n",
      "8cd73e8eed69: Preparing\n",
      "68fc9618299b: Preparing\n",
      "aab9079a62d1: Preparing\n",
      "ac5349f9af57: Preparing\n",
      "47a79b5a2369: Preparing\n",
      "42958de951d6: Preparing\n",
      "6effad8e07e5: Preparing\n",
      "62cbb606ac4a: Preparing\n",
      "8c93aa82e26a: Preparing\n",
      "4b9202833b21: Preparing\n",
      "20048f8d31de: Preparing\n",
      "c890837d995f: Preparing\n",
      "fcd654f1dc27: Preparing\n",
      "becec4c05380: Preparing\n",
      "8d267010480f: Preparing\n",
      "270f934787ed: Preparing\n",
      "02571d034293: Preparing\n",
      "47a79b5a2369: Waiting\n",
      "42958de951d6: Waiting\n",
      "6effad8e07e5: Waiting\n",
      "62cbb606ac4a: Waiting\n",
      "8c93aa82e26a: Waiting\n",
      "4b9202833b21: Waiting\n",
      "20048f8d31de: Waiting\n",
      "c890837d995f: Waiting\n",
      "fcd654f1dc27: Waiting\n",
      "becec4c05380: Waiting\n",
      "8d267010480f: Waiting\n",
      "270f934787ed: Waiting\n",
      "02571d034293: Waiting\n",
      "ac5349f9af57: Layer already exists\n",
      "47a79b5a2369: Layer already exists\n",
      "42958de951d6: Layer already exists\n",
      "6effad8e07e5: Layer already exists\n",
      "8cd73e8eed69: Pushed\n",
      "68fc9618299b: Pushed\n",
      "62cbb606ac4a: Layer already exists\n",
      "20048f8d31de: Layer already exists\n",
      "8c93aa82e26a: Layer already exists\n",
      "4b9202833b21: Layer already exists\n",
      "c890837d995f: Layer already exists\n",
      "becec4c05380: Layer already exists\n",
      "fcd654f1dc27: Layer already exists\n",
      "8d267010480f: Layer already exists\n",
      "02571d034293: Layer already exists\n",
      "270f934787ed: Layer already exists\n",
      "aab9079a62d1: Pushed\n",
      "6d2b28061301: Pushed\n",
      "latest: digest: sha256:94492d0cd0059cd980712074a225ca3ff3843c530bde0d7fec1acb3ba955cf63 size: 4103\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                         IMAGES                                                          STATUS\n",
      "c108bb97-9286-4241-ade1-615e2163ecce  2020-03-23T00:29:48+00:00  5M17S     gs://natural-questions-v1_cloudbuild/source/1584923304.9-3d97c16d9850449b96b36bb20c962c72.tgz  gcr.io/natural-questions-v1/nq-submission-bert-joint (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create docker build\n",
    "!gcloud auth login\n",
    "Y\n",
    "!gcloud config set project natural-questions-v1\n",
    "!gcloud builds submit --tag gcr.io/natural-questions-v1/nq-submission-bert-joint ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Official Attempt Submission to Google Natural Questons Competition Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dashboard](img/dashboard.JPG)\n",
    "![leaderboards](img/leaderboards.JPG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
